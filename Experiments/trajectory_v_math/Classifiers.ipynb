{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib qt\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.datasets import imdb\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM, RNN, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype float128 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "pos_set = np.load(\"./train/pos_set.npy\")\n",
    "neg_set = np.load(\"./train/neg_set.npy\")\n",
    "\n",
    "complete = np.concatenate((pos_set, neg_set))\n",
    "y = np.concatenate((np.ones((pos_set.shape[0],1)), np.zeros((neg_set.shape[0],1))))\n",
    "\n",
    "scaled_data = []\n",
    "\n",
    "for trajectory in complete:\n",
    "    std = StandardScaler()\n",
    "    scaled_data.append(std.fit_transform(trajectory))\n",
    "\n",
    "scaled_data = np.asarray(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1933, 999, 2), (1933, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_data, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(126, input_shape=(999, 2), return_sequences=True, dropout=0.2))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(16, dropout=0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 999, 126)          65016     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 999, 64)           48896     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 16)                5184      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 119,113\n",
      "Trainable params: 119,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1014 samples, validate on 435 samples\n",
      "Epoch 1/10\n",
      "1014/1014 [==============================] - 68s 67ms/step - loss: 0.1371 - acc: 0.9645 - val_loss: 0.0437 - val_acc: 0.9977\n",
      "Epoch 2/10\n",
      "1014/1014 [==============================] - 67s 66ms/step - loss: 0.1347 - acc: 0.9645 - val_loss: 0.0438 - val_acc: 0.9954\n",
      "Epoch 3/10\n",
      "1014/1014 [==============================] - 67s 67ms/step - loss: 0.1928 - acc: 0.9310 - val_loss: 0.1147 - val_acc: 0.9379\n",
      "Epoch 4/10\n",
      "1014/1014 [==============================] - 68s 67ms/step - loss: 0.2212 - acc: 0.9142 - val_loss: 0.0943 - val_acc: 0.9770\n",
      "Epoch 5/10\n",
      "1014/1014 [==============================] - 68s 67ms/step - loss: 0.1615 - acc: 0.9467 - val_loss: 0.1256 - val_acc: 0.9701\n",
      "Epoch 6/10\n",
      "1014/1014 [==============================] - 68s 67ms/step - loss: 0.1098 - acc: 0.9655 - val_loss: 0.0526 - val_acc: 0.9977\n",
      "Epoch 7/10\n",
      "1014/1014 [==============================] - 67s 67ms/step - loss: 0.1188 - acc: 0.9625 - val_loss: 0.2481 - val_acc: 0.9540\n",
      "Epoch 8/10\n",
      "1014/1014 [==============================] - 69s 68ms/step - loss: 0.1976 - acc: 0.9458 - val_loss: 0.0504 - val_acc: 0.9908\n",
      "Epoch 9/10\n",
      "1014/1014 [==============================] - 67s 66ms/step - loss: 0.1508 - acc: 0.9625 - val_loss: 0.1124 - val_acc: 0.9724\n",
      "Epoch 10/10\n",
      "1014/1014 [==============================] - 68s 67ms/step - loss: 0.1300 - acc: 0.9596 - val_loss: 0.0545 - val_acc: 0.9885\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    validation_split=0.3,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[ModelCheckpoint(\"./models_lstm1/weights.{epoch:02d}-{val_loss:.2f}.hdf5\")]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484/484 [==============================] - 5s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.040990727638040694, 0.993801652892562]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-e10366a88f2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(range(1,11),history.history[\"val_acc\"], label=\"Validation Accuracy\")\n",
    "plt.plot(range(1,11), history.history[\"acc\"], label=\"Training Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_test = load_model(\"./models_lstm1/weights.10-0.05.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1739/1739 [==============================] - 183s 105ms/step - loss: 0.5643 - acc: 0.7269\n",
      "Epoch 2/4\n",
      "1739/1739 [==============================] - 180s 103ms/step - loss: 0.4589 - acc: 0.8079\n",
      "Epoch 3/4\n",
      "1739/1739 [==============================] - 179s 103ms/step - loss: 0.5636 - acc: 0.7430\n",
      "Epoch 4/4\n",
      "1739/1739 [==============================] - 177s 102ms/step - loss: 0.3950 - acc: 0.8419\n",
      "evaluating model\n",
      "acc: 97.94%\n",
      "training accuracy: 0.81\n",
      "\n",
      "\n",
      "\n",
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1739/1739 [==============================] - 182s 105ms/step - loss: 0.5192 - acc: 0.7660\n",
      "Epoch 2/4\n",
      "1739/1739 [==============================] - 177s 102ms/step - loss: 0.3727 - acc: 0.8534\n",
      "Epoch 3/4\n",
      "1739/1739 [==============================] - 178s 102ms/step - loss: 0.3029 - acc: 0.8930\n",
      "Epoch 4/4\n",
      "1739/1739 [==============================] - 179s 103ms/step - loss: 0.3013 - acc: 0.8976\n",
      "evaluating model\n",
      "acc: 98.97%\n",
      "training accuracy: 0.85\n",
      "\n",
      "\n",
      "\n",
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1739/1739 [==============================] - 185s 106ms/step - loss: 0.5402 - acc: 0.7280\n",
      "Epoch 2/4\n",
      "1739/1739 [==============================] - 179s 103ms/step - loss: 0.4870 - acc: 0.7953\n",
      "Epoch 3/4\n",
      "1739/1739 [==============================] - 178s 103ms/step - loss: 0.3602 - acc: 0.8723\n",
      "Epoch 4/4\n",
      "1739/1739 [==============================] - 179s 103ms/step - loss: 0.3196 - acc: 0.8873\n",
      "evaluating model\n",
      "acc: 95.88%\n",
      "training accuracy: 0.80\n",
      "\n",
      "\n",
      "\n",
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1739/1739 [==============================] - 185s 106ms/step - loss: 0.5134 - acc: 0.7539\n",
      "Epoch 2/4\n",
      "1739/1739 [==============================] - 179s 103ms/step - loss: 0.3319 - acc: 0.8781\n",
      "Epoch 3/4\n",
      "1739/1739 [==============================] - 178s 102ms/step - loss: 0.2963 - acc: 0.8913\n",
      "Epoch 4/4\n",
      "1739/1739 [==============================] - 179s 103ms/step - loss: 0.2937 - acc: 0.9017\n",
      "evaluating model\n",
      "acc: 97.42%\n",
      "training accuracy: 0.88\n",
      "\n",
      "\n",
      "\n",
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1739/1739 [==============================] - 186s 107ms/step - loss: 0.4931 - acc: 0.7821\n",
      "Epoch 2/4\n",
      "1739/1739 [==============================] - 179s 103ms/step - loss: 0.5008 - acc: 0.7780\n",
      "Epoch 3/4\n",
      "1739/1739 [==============================] - 179s 103ms/step - loss: 0.4436 - acc: 0.8344\n",
      "Epoch 4/4\n",
      "1739/1739 [==============================] - 179s 103ms/step - loss: 0.5141 - acc: 0.7366\n",
      "evaluating model\n",
      "acc: 92.27%\n",
      "training accuracy: 0.78\n",
      "\n",
      "\n",
      "\n",
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1739/1739 [==============================] - 184s 106ms/step - loss: 0.5628 - acc: 0.7332\n",
      "Epoch 2/4\n",
      "1739/1739 [==============================] - 178s 102ms/step - loss: 0.6211 - acc: 0.6671\n",
      "Epoch 3/4\n",
      "1739/1739 [==============================] - 179s 103ms/step - loss: 0.6234 - acc: 0.6256\n",
      "Epoch 4/4\n",
      "1739/1739 [==============================] - 179s 103ms/step - loss: 0.4337 - acc: 0.8367\n",
      "evaluating model\n",
      "acc: 73.71%\n",
      "training accuracy: 0.67\n",
      "\n",
      "\n",
      "\n",
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1740/1740 [==============================] - 185s 106ms/step - loss: 0.5412 - acc: 0.7293\n",
      "Epoch 2/4\n",
      "1740/1740 [==============================] - 179s 103ms/step - loss: 0.4922 - acc: 0.7983\n",
      "Epoch 3/4\n",
      "1740/1740 [==============================] - 179s 103ms/step - loss: 0.4620 - acc: 0.7747\n",
      "Epoch 4/4\n",
      "1740/1740 [==============================] - 177s 102ms/step - loss: 0.3831 - acc: 0.8460\n",
      "evaluating model\n",
      "acc: 95.34%\n",
      "training accuracy: 0.80\n",
      "\n",
      "\n",
      "\n",
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1741/1741 [==============================] - 184s 106ms/step - loss: 0.5530 - acc: 0.7381\n",
      "Epoch 2/4\n",
      "1741/1741 [==============================] - 177s 102ms/step - loss: 0.5507 - acc: 0.7352\n",
      "Epoch 3/4\n",
      "1741/1741 [==============================] - 178s 102ms/step - loss: 0.4310 - acc: 0.8070\n",
      "Epoch 4/4\n",
      "1741/1741 [==============================] - 177s 102ms/step - loss: 0.3008 - acc: 0.8966\n",
      "evaluating model\n",
      "acc: 72.92%\n",
      "training accuracy: 0.74\n",
      "\n",
      "\n",
      "\n",
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1741/1741 [==============================] - 185s 106ms/step - loss: 0.6271 - acc: 0.6410\n",
      "Epoch 2/4\n",
      "1741/1741 [==============================] - 179s 103ms/step - loss: 0.5307 - acc: 0.7582\n",
      "Epoch 3/4\n",
      "1741/1741 [==============================] - 178s 102ms/step - loss: 0.5709 - acc: 0.6847\n",
      "Epoch 4/4\n",
      "1741/1741 [==============================] - 179s 103ms/step - loss: 0.5148 - acc: 0.7593\n",
      "evaluating model\n",
      "acc: 67.19%\n",
      "training accuracy: 0.76\n",
      "\n",
      "\n",
      "\n",
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1741/1741 [==============================] - 188s 108ms/step - loss: 0.5718 - acc: 0.7007\n",
      "Epoch 2/4\n",
      "1741/1741 [==============================] - 180s 103ms/step - loss: 0.4664 - acc: 0.7944\n",
      "Epoch 3/4\n",
      "1741/1741 [==============================] - 179s 103ms/step - loss: 0.3978 - acc: 0.8627\n",
      "Epoch 4/4\n",
      "1741/1741 [==============================] - 180s 103ms/step - loss: 0.2769 - acc: 0.9098\n",
      "evaluating model\n",
      "acc: 99.48%\n",
      "training accuracy: 0.79\n",
      "\n",
      "\n",
      "\n",
      "89.11% (+/- 11.94%)\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(scaled_data, y):\n",
    "  # create model\n",
    "    print(\"making model\")\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(999, 2), return_sequences=True, dropout=0.2))\n",
    "    model.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
    "    model.add(LSTM(16))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    # Compile model\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    print(\"training model\")\n",
    "    history = model.fit(scaled_data[train], y[train], epochs=4)\n",
    "    # evaluate the model\n",
    "    print(\"evaluating model\")\n",
    "    scores = model.evaluate(scaled_data[test], y[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"training accuracy: %.2f\" %(history.history[\"acc\"])[1])\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    print(\"\\n\\n\")\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv1D(64, 7, activation=\"relu\", input_shape=(999,2)))\n",
    "model_cnn.add(MaxPooling1D(5))\n",
    "model_cnn.add(Conv1D(64, 7, activation=\"relu\"))\n",
    "model_cnn.add(GlobalMaxPooling1D())\n",
    "model_cnn.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 993, 64)           960       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 198, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 192, 64)           28736     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 29,761\n",
      "Trainable params: 29,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.compile(optimizer=\"rmsprop\",\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1014 samples, validate on 435 samples\n",
      "Epoch 1/10\n",
      "1014/1014 [==============================] - 5s 5ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "1014/1014 [==============================] - 5s 5ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.5493e-04 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "1014/1014 [==============================] - 5s 5ms/step - loss: 2.0425e-04 - acc: 1.0000 - val_loss: 1.6279e-04 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "1014/1014 [==============================] - 5s 5ms/step - loss: 6.5555e-05 - acc: 1.0000 - val_loss: 1.6338e-04 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "1014/1014 [==============================] - 5s 5ms/step - loss: 2.0829e-05 - acc: 1.0000 - val_loss: 5.2606e-05 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "1014/1014 [==============================] - 5s 5ms/step - loss: 6.5786e-06 - acc: 1.0000 - val_loss: 2.3364e-05 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "1014/1014 [==============================] - 5s 5ms/step - loss: 3.0762e-06 - acc: 1.0000 - val_loss: 4.1011e-06 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "1014/1014 [==============================] - 5s 5ms/step - loss: 2.4621e-06 - acc: 1.0000 - val_loss: 2.8839e-06 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "1014/1014 [==============================] - 5s 5ms/step - loss: 2.6185e-07 - acc: 1.0000 - val_loss: 9.6498e-07 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "1014/1014 [==============================] - 5s 5ms/step - loss: 2.5824e-07 - acc: 1.0000 - val_loss: 4.3403e-06 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history_cnn = model_cnn.fit(X_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_split=0.3,\n",
    "    shuffle=True,\n",
    "    callbacks=[ModelCheckpoint(\"./models_1Dcnn/weights.{epoch:02d}-{val_loss:.2f}.hdf5\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.1775 - acc: 0.9661\n",
      "Epoch 2/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.0210 - acc: 0.9971\n",
      "Epoch 3/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.0062 - acc: 0.9988\n",
      "Epoch 4/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.0022 - acc: 1.0000\n",
      "evaluating model\n",
      "acc: 100.00%\n",
      "training accuracy: 1.00\n",
      "\n",
      "\n",
      "\n",
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.1788 - acc: 0.9776\n",
      "Epoch 2/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.0195 - acc: 0.9983\n",
      "Epoch 3/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.0058 - acc: 0.9983\n",
      "Epoch 4/4\n",
      "1739/1739 [==============================] - 11s 7ms/step - loss: 0.0021 - acc: 0.9994\n",
      "evaluating model\n",
      "acc: 100.00%\n",
      "training accuracy: 1.00\n",
      "\n",
      "\n",
      "\n",
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.2457 - acc: 0.9632\n",
      "Epoch 2/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.0291 - acc: 0.9977\n",
      "Epoch 3/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.0066 - acc: 0.9983\n",
      "Epoch 4/4\n",
      "1739/1739 [==============================] - 11s 7ms/step - loss: 0.0015 - acc: 1.0000\n",
      "evaluating model\n",
      "acc: 100.00%\n",
      "training accuracy: 1.00\n",
      "\n",
      "\n",
      "\n",
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.2104 - acc: 0.9701\n",
      "Epoch 2/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.0227 - acc: 0.9983\n",
      "Epoch 3/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.0054 - acc: 0.9994\n",
      "Epoch 4/4\n",
      "1739/1739 [==============================] - 11s 7ms/step - loss: 0.0017 - acc: 1.0000\n",
      "evaluating model\n",
      "acc: 100.00%\n",
      "training accuracy: 1.00\n",
      "\n",
      "\n",
      "\n",
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.2140 - acc: 0.9597\n",
      "Epoch 2/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.0234 - acc: 0.9988\n",
      "Epoch 3/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.0060 - acc: 0.9994\n",
      "Epoch 4/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.0026 - acc: 0.9994\n",
      "evaluating model\n",
      "acc: 100.00%\n",
      "training accuracy: 1.00\n",
      "\n",
      "\n",
      "\n",
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1739/1739 [==============================] - 13s 7ms/step - loss: 0.1930 - acc: 0.9638\n",
      "Epoch 2/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.0202 - acc: 0.9983\n",
      "Epoch 3/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.0068 - acc: 0.9988\n",
      "Epoch 4/4\n",
      "1739/1739 [==============================] - 12s 7ms/step - loss: 0.0037 - acc: 0.9994\n",
      "evaluating model\n",
      "acc: 99.48%\n",
      "training accuracy: 1.00\n",
      "\n",
      "\n",
      "\n",
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1740/1740 [==============================] - 12s 7ms/step - loss: 0.2356 - acc: 0.9552\n",
      "Epoch 2/4\n",
      "1740/1740 [==============================] - 12s 7ms/step - loss: 0.0243 - acc: 0.9983\n",
      "Epoch 3/4\n",
      "1740/1740 [==============================] - 11s 7ms/step - loss: 0.0057 - acc: 0.9989\n",
      "Epoch 4/4\n",
      "1740/1740 [==============================] - 12s 7ms/step - loss: 0.0019 - acc: 0.9994\n",
      "evaluating model\n",
      "acc: 99.48%\n",
      "training accuracy: 1.00\n",
      "\n",
      "\n",
      "\n",
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1741/1741 [==============================] - 12s 7ms/step - loss: 0.1943 - acc: 0.9661\n",
      "Epoch 2/4\n",
      "1741/1741 [==============================] - 11s 7ms/step - loss: 0.0210 - acc: 0.9977\n",
      "Epoch 3/4\n",
      "1741/1741 [==============================] - 12s 7ms/step - loss: 0.0048 - acc: 0.9994\n",
      "Epoch 4/4\n",
      "1741/1741 [==============================] - 12s 7ms/step - loss: 0.0014 - acc: 1.0000\n",
      "evaluating model\n",
      "acc: 100.00%\n",
      "training accuracy: 1.00\n",
      "\n",
      "\n",
      "\n",
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1741/1741 [==============================] - 13s 7ms/step - loss: 0.2010 - acc: 0.9615\n",
      "Epoch 2/4\n",
      "1741/1741 [==============================] - 12s 7ms/step - loss: 0.0206 - acc: 0.9983\n",
      "Epoch 3/4\n",
      "1741/1741 [==============================] - 12s 7ms/step - loss: 0.0052 - acc: 0.9989\n",
      "Epoch 4/4\n",
      "1741/1741 [==============================] - 12s 7ms/step - loss: 0.0025 - acc: 0.9994\n",
      "evaluating model\n",
      "acc: 100.00%\n",
      "training accuracy: 1.00\n",
      "\n",
      "\n",
      "\n",
      "making model\n",
      "training model\n",
      "Epoch 1/4\n",
      "1741/1741 [==============================] - 13s 7ms/step - loss: 0.2007 - acc: 0.9632\n",
      "Epoch 2/4\n",
      "1741/1741 [==============================] - 12s 7ms/step - loss: 0.0205 - acc: 0.9989\n",
      "Epoch 3/4\n",
      "1741/1741 [==============================] - 12s 7ms/step - loss: 0.0044 - acc: 0.9989\n",
      "Epoch 4/4\n",
      "1741/1741 [==============================] - 12s 7ms/step - loss: 0.0010 - acc: 1.0000\n",
      "evaluating model\n",
      "acc: 99.48%\n",
      "training accuracy: 1.00\n",
      "\n",
      "\n",
      "\n",
      "99.84% (+/- 0.24%)\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(scaled_data, y):\n",
    "  # create model\n",
    "    print(\"making model\")\n",
    "    model_cnn = Sequential()\n",
    "    model_cnn.add(Conv1D(64, 4, activation=\"relu\", input_shape=(999,2)))\n",
    "    model_cnn.add(MaxPooling1D(2))\n",
    "    model_cnn.add(Conv1D(64, 4, activation=\"relu\"))\n",
    "    model_cnn.add(GlobalMaxPooling1D())\n",
    "    model_cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "    # Compile model\n",
    "    \n",
    "    model_cnn.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    print(\"training model\")\n",
    "    history = model_cnn.fit(scaled_data[train], y[train], epochs=4)\n",
    "    # evaluate the model\n",
    "    print(\"evaluating model\")\n",
    "    scores = model_cnn.evaluate(scaled_data[test], y[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model_cnn.metrics_names[1], scores[1]*100))\n",
    "    print(\"training accuracy: %.2f\" %(history.history[\"acc\"])[1])\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    print(\"\\n\\n\")\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "layer_outputs = [layer.output for layer in model_cnn.layers[:2]]\n",
    "activation_model = models.Model(inputs=model_cnn.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = activation_model.predict(X_train[0].reshape((1,999,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named matplotlib.pyplot",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-452cf3c61a45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_layer_activation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'viridis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named matplotlib.pyplot"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(first_layer_activation[0, :, :, 4], cmap='viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
